import torch
from transformers import AutoModelForSemanticSegmentation, AutoImageProcessor
import onnx
import os

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
model_id = "leftattention/segformer-b4-wall"
output_path = "segformer-b4-wall.onnx"

print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ Hugging Face...")
try:
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    model = AutoModelForSemanticSegmentation.from_pretrained(model_id)
    processor = AutoImageProcessor.from_pretrained(model_id)
    
    # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ —Ä–µ–∂–∏–º eval
    model.eval()
    
    print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
    print(f"üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏:")
    print(f"   - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: {model.config.num_labels}")
    print(f"   - –†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {processor.size}")
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–∑–º–µ—Ä –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
    height = processor.size.get("height", 512)
    width = processor.size.get("width", 512)
    dummy_input = torch.randn(1, 3, height, width)
    
    print(f"üîß –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX —Ñ–æ—Ä–º–∞—Ç...")
    print(f"   - –í—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä: [1, 3, {height}, {width}]")
    
    # –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX
    torch.onnx.export(
        model,
        dummy_input,
        output_path,
        input_names=['pixel_values'],
        output_names=['logits'],
        opset_version=13,
        export_params=True,
        do_constant_folding=True,
        dynamic_axes={
            'pixel_values': {0: 'batch_size'},
            'logits': {0: 'batch_size'}
        }
    )
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–π —Ñ–∞–π–ª
    if os.path.exists(output_path):
        file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB
        print(f"‚úÖ –£–°–ü–ï–•! –ú–æ–¥–µ–ª—å —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞:")
        print(f"   - –§–∞–π–ª: {output_path}")
        print(f"   - –†–∞–∑–º–µ—Ä: {file_size:.1f} MB")
        print(f"")
        print(f"üéØ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print(f"   1. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ —Ñ–∞–π–ª '{output_path}' –≤ –ø–∞–ø–∫—É Assets/Models/ –≤–∞—à–µ–≥–æ Unity –ø—Ä–æ–µ–∫—Ç–∞")
        print(f"   2. –í AsyncSegmentationManager –≤—ã–±–µ—Ä–∏—Ç–µ —ç—Ç—É –º–æ–¥–µ–ª—å")
        print(f"   3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å—Ü–µ–Ω—É")
    else:
        print("‚ùå –û—à–∏–±–∫–∞: —Ñ–∞–π–ª –Ω–µ –±—ã–ª —Å–æ–∑–¥–∞–Ω")
        
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–ª–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}")
    print("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ:")
    print("   - –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ")
    print("   - –ü–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫–∏: pip install --upgrade transformers torch")