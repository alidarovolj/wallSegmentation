// –û—Å–Ω–æ–≤–Ω–æ–π SegmentationManager —Å Sentis 2.0
// –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω –∏–∑ SegmentationManagerSentis –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
// –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π Sentis API –¥–ª—è Unity 6.0

using System.Collections;
using System.Collections.Generic;
using System.Linq;
using TMPro;
using Unity.Sentis;
using UnityEngine;
using UnityEngine.Rendering;
using UnityEngine.UI;
using UnityEngine.XR.ARFoundation;
using UnityEngine.XR.ARSubsystems;

public class SegmentationManager : MonoBehaviour
{
      [Header("Model Configuration")]
      [SerializeField] private ModelAsset modelAsset;
      [SerializeField] private BackendType workerType = BackendType.GPUCompute;
      [SerializeField] private Vector2Int overrideResolution = new Vector2Int(512, 512);

      [Header("UI Components")]
      [SerializeField] private ARCameraManager arCameraManager;
      [SerializeField] private RawImage segmentationDisplay; // Changed from rawImage
      [SerializeField] private TextMeshProUGUI classNameText;

      [Header("Painting")]
      [SerializeField] private PaintManager paintManager; // Reference to the new PaintManager

      [Header("Performance")]
      [Tooltip("How long the class name stays on screen in seconds.")]
      [SerializeField] private float displayNameDuration = 1.5f;

      [Header("Rendering")]
      [SerializeField] private ComputeShader postProcessShader;
      [SerializeField] private int classIndexToPaint = -1; // Default to all classes
      [SerializeField] private int classIndexToPaint2 = -1; // Second class to paint
      [SerializeField, Range(0.1f, 10f)] private float edgeHardness = 2.5f; // Controls edge smoothness
      [SerializeField] private Color paintColor = Color.blue;
      [SerializeField] private bool mirrorX = false;
      [SerializeField] private bool mirrorY = true;

      [Header("Preprocessing")]
      [SerializeField] private ComputeShader preprocessorShader;
      private RenderTexture preprocessedTexture;
      private int preprocessKernel;

      // Model-related resources
      private Model runtimeModel;
      private Worker worker;

      // GPU resources
      private RenderTexture segmentationTexture;
      private ComputeBuffer tensorDataBuffer;
      private ComputeBuffer colorMapBuffer;
      private int postProcessKernel;

      // Processing state
      private Vector2Int imageSize;
      private float[] lastTensorData; // Cached tensor data for tap handling
      private TensorShape lastTensorShape; // Cached shape for tap handling
      private int numClasses = 21;
      private bool isProcessing = false;
      private Coroutine displayNameCoroutine;

      // Class names and colors
      private readonly List<Color> colorMap = new List<Color>();

      void Start()
      {
            // Initialize color map
            var colors = ColorMap.GetAllColors();
            colorMap.AddRange(colors);

            StartCoroutine(InitializeSentis());
      }

      void OnEnable()
      {
            if (arCameraManager != null)
            {
                  arCameraManager.frameReceived += OnCameraFrameReceived;
                  Debug.Log("üì∑ AR Camera frame processing enabled");
            }
      }

      void OnDisable()
      {
            if (arCameraManager != null)
            {
                  arCameraManager.frameReceived -= OnCameraFrameReceived;
                  Debug.Log("üì∑ AR Camera frame processing disabled");
            }
      }

      private IEnumerator InitializeSentis()
      {
            Debug.Log("üöÄ Initializing Sentis ML mode...");
            runtimeModel = ModelLoader.Load(modelAsset);

            DetermineInputResolution();

            // Initialize GPU resources with the correct image size
            InitializeGpuResources();

            worker = new Worker(runtimeModel, workerType);
            Debug.Log($"‚úÖ Sentis worker created with {workerType} backend");

            Debug.Log("üéâ Sentis initialization completed!");
            yield return null;
            DiagnoseCameraBackground();
      }

      private void DetermineInputResolution()
      {
            if (overrideResolution.x > 0 && overrideResolution.y > 0)
            {
                  imageSize = overrideResolution;
                  Debug.Log($"‚úÖ Using override resolution: {imageSize}");
            }
            else
            {
                  // Fallback for safety, though override should always be set.
                  imageSize = new Vector2Int(512, 512);
                  Debug.LogWarning("‚ö†Ô∏è Override resolution not set. Using fallback 512x512.");
            }
      }

      private void InitializeGpuResources()
      {
            // Create a render texture for the segmentation mask
            segmentationTexture = new RenderTexture(imageSize.x, imageSize.y, 0, RenderTextureFormat.ARGB32);
            segmentationTexture.enableRandomWrite = true;
            segmentationTexture.Create();

            // Create a render texture for preprocessing
            preprocessedTexture = new RenderTexture(imageSize.x, imageSize.y, 0, RenderTextureFormat.ARGBFloat);
            preprocessedTexture.enableRandomWrite = true;
            preprocessedTexture.Create();

            // Initialize the preprocessor shader
            if (preprocessorShader != null)
            {
                  preprocessKernel = preprocessorShader.FindKernel("Preprocess");
                  preprocessorShader.SetTexture(preprocessKernel, "OutputTexture", preprocessedTexture);
            }

            // Get the kernel index for the post-processing shader.
            postProcessKernel = postProcessShader.FindKernel("CSMain");
            postProcessShader.SetTexture(postProcessKernel, "OutputTexture", segmentationTexture);

            // Setup color map for visualization
            if (colorMap.Count > 0)
            {
                  colorMapBuffer = new ComputeBuffer(colorMap.Count, sizeof(float) * 4);
                  colorMapBuffer.SetData(colorMap);
                  postProcessShader.SetBuffer(postProcessKernel, "ColorMap", colorMapBuffer);
                  postProcessShader.SetInt("numClasses", colorMap.Count);
            }

            // Assign to UI
            if (segmentationDisplay != null)
            {
                  segmentationDisplay.texture = segmentationTexture;
                  Debug.Log("‚úÖ RawImage texture assigned");
            }

            Debug.Log("‚úÖ GPU resources initialized for ML processing");
      }

      private void OnCameraFrameReceived(ARCameraFrameEventArgs eventArgs)
      {
            if (isProcessing || worker == null) return;

            if (!arCameraManager.TryAcquireLatestCpuImage(out XRCpuImage image))
            {
                  return;
            }

            StartCoroutine(ProcessFrame(image));
      }

      private IEnumerator ProcessFrame(XRCpuImage image)
      {
            isProcessing = true;
            Debug.Log("üîÑ Starting camera image processing...");

            var conversionParams = new XRCpuImage.ConversionParams
            {
                  inputRect = new RectInt(0, 0, image.width, image.height),
                  outputDimensions = new Vector2Int(imageSize.x, imageSize.y),
                  outputFormat = TextureFormat.RGBA32,
                  transformation = XRCpuImage.Transformation.MirrorY // Apply vertical flip consistently
            };

            var texture = new Texture2D(imageSize.x, imageSize.y, conversionParams.outputFormat, false);
            image.Convert(conversionParams, texture.GetRawTextureData<byte>());
            texture.Apply();
            image.Dispose();

            if (preprocessorShader != null)
            {
                  preprocessorShader.SetTexture(preprocessKernel, "InputTexture", texture);
                  int threadGroupsX = Mathf.CeilToInt(imageSize.x / 8.0f);
                  int threadGroupsY = Mathf.CeilToInt(imageSize.y / 8.0f);
                  preprocessorShader.Dispatch(preprocessKernel, threadGroupsX, threadGroupsY, 1);
            }

            using (var inputTensor = TextureConverter.ToTensor(preprocessorShader != null ? (Texture)preprocessedTexture : texture))
            {
                  worker.Schedule(inputTensor);
            }
            Destroy(texture);

            yield return new WaitForEndOfFrame();

            var outputTensor = worker.PeekOutput() as Tensor<float>;
            if (outputTensor == null)
            {
                  Debug.LogError("‚ùå Failed to peek output tensor.");
                  isProcessing = false;
                  yield break;
            }

            var tensorData = outputTensor.DownloadToArray();
            var shape = outputTensor.shape;

            // Cache tensor data for tap handling
            lastTensorData = tensorData;
            lastTensorShape = shape;

            outputTensor.Dispose();

            if (tensorData == null || tensorData.Length == 0)
            {
                  Debug.LogError("‚ùå Tensor data is empty or null after download.");
                  isProcessing = false;
                  yield break;
            }

            if (tensorDataBuffer == null || tensorDataBuffer.count != tensorData.Length)
            {
                  tensorDataBuffer?.Dispose();
                  tensorDataBuffer = new ComputeBuffer(tensorData.Length, sizeof(float));
                  postProcessShader.SetBuffer(postProcessKernel, "TensorData", tensorDataBuffer);
            }
            tensorDataBuffer.SetData(tensorData);

            postProcessShader.SetInt("tensorWidth", shape[3]);
            postProcessShader.SetInt("tensorHeight", shape[2]);
            this.numClasses = shape[1];
            postProcessShader.SetInt("numClasses", this.numClasses);
            postProcessShader.SetInt("classIndexToPaint", classIndexToPaint);
            postProcessShader.SetInt("classIndexToPaint2", classIndexToPaint2);
            postProcessShader.SetFloat("edgeHardness", edgeHardness);

            int threadGroupsX_post = Mathf.CeilToInt(segmentationTexture.width / 8.0f);
            int threadGroupsY_post = Mathf.CeilToInt(segmentationTexture.height / 8.0f);
            postProcessShader.Dispatch(postProcessKernel, threadGroupsX_post, threadGroupsY_post, 1);

            // --- NEW: Update PaintManager every frame ---
            if (paintManager != null)
            {
                  paintManager.UpdateSegmentationTexture(segmentationTexture);
            }

            Debug.Log("‚úÖ Segmentation processing completed!");
            isProcessing = false;
      }

      void OnDestroy()
      {
            worker?.Dispose();

            tensorDataBuffer?.Release();
            colorMapBuffer?.Release();

            if (segmentationTexture != null) segmentationTexture.Release();
            if (preprocessedTexture != null) preprocessedTexture.Release();
      }

      // Public methods for UI control
      public void SetClassToPaint(int classIndex)
      {
            classIndexToPaint = classIndex;
            classIndexToPaint2 = -1; // Reset second class
            Debug.Log($"üé® Class to paint set to: {classIndex}");
      }

      public void ShowAllClasses()
      {
            classIndexToPaint = -1;
            classIndexToPaint2 = -1;
            Debug.Log("üåà Showing all classes");
      }

      public void ToggleTestMode()
      {
            // This method is no longer relevant as test mode is removed.
            // Keeping it for now, but it will do nothing.
            Debug.Log("üîÑ ToggleTestMode called, but test mode is removed.");
      }

      [ContextMenu("Test ML Model")]
      public void TestMLModel()
      {
            // This method is no longer relevant as test mode is removed.
            // Keeping it for now, but it will do nothing.
            Debug.Log("üß™ TestMLModel called, but test mode is removed.");
      }

      [ContextMenu("Visualize Model Output")]
      public void VisualizeModelOutput()
      {
            Debug.Log($"üîç VisualizeModelOutput Debug:");
            Debug.Log($"   worker != null: {worker != null}");
            Debug.Log($"   runtimeModel != null: {runtimeModel != null}");
            Debug.Log($"   postProcessShader != null: {postProcessShader != null}");
            Debug.Log($"   segmentationTexture != null: {segmentationTexture != null}");
            Debug.Log($"   segmentationDisplay != null: {segmentationDisplay != null}");
            Debug.Log($"   rawImage != null: {arCameraManager != null && arCameraManager.GetComponent<RawImage>() != null}"); // Assuming rawImage is the ARCameraBackground's texture

            if (worker != null)
            {
                  Debug.Log("üé® Creating simple test data to visualize model output...");
                  StartCoroutine(CreateSimpleTestData());
            }
            else
            {
                  Debug.Log("‚ö†Ô∏è ML model not loaded yet");
                  if (worker == null) Debug.Log("   - worker is null");
            }
      }

      [ContextMenu("Show Only Chairs")]
      public void ShowOnlyChairs()
      {
            classIndexToPaint = 19; // ADE20K index for chair
            classIndexToPaint2 = -1;
            Debug.Log("üé® Showing only: chair (19)");
      }

      [ContextMenu("Show Only Walls")]
      public void ShowOnlyWalls()
      {
            classIndexToPaint = 0; // Correct ADE20K index for 'wall' is 0 for this model
            classIndexToPaint2 = -1;
            Debug.Log("üé® Showing only: wall (0)");
      }

      [ContextMenu("Show Walls and Floor")]
      public void ShowWallsAndFloor()
      {
          classIndexToPaint = 0; // wall
          classIndexToPaint2 = 3; // floor
          Debug.Log("üé® Showing only: wall (0) and floor (3)");
      }

      // =====================================================
      // INTERACTIVE TAP HANDLING
      // =====================================================

      private void Update()
      {
            HandleTap();
      }

      private void HandleTap()
      {
            if (Input.GetMouseButtonDown(0))
            {
                  if (lastTensorData == null || lastTensorShape.rank == 0) return;

                  Vector2 screenPos = Input.mousePosition;

                  // Convert screen position to UV coordinates (0-1 range)
                  // Note: This assumes the segmentationDisplay RawImage covers the full screen.
                  // If not, you'll need RectTransformUtility.ScreenPointToLocalPointInRectangle.
                  float uv_x = screenPos.x / Screen.width;
                  float uv_y = screenPos.y / Screen.height;

                  // Flip coordinates to match our shader logic if necessary
                  // Based on our last fix, both are inverted.
                  uv_x = 1.0f - uv_x;
                  uv_y = 1.0f - uv_y;

                  // Convert UV coordinates to tensor coordinates
                  int tensorX = (int)(uv_x * lastTensorShape[3]);
                  int tensorY = (int)(uv_y * lastTensorShape[2]);

                  // --- Perform Argmax on CPU for the tapped pixel ---
                  int tappedClass = 0;
                  float maxLogit = float.MinValue;
                  int tensorWidth = lastTensorShape[3];
                  int tensorHeight = lastTensorShape[2];

                  for (int c = 0; c < numClasses; c++)
                  {
                        int logitIndex = c * (tensorWidth * tensorHeight) + tensorY * tensorWidth + tensorX;
                        if (logitIndex < lastTensorData.Length)
                        {
                              float currentLogit = lastTensorData[logitIndex];
                              if (currentLogit > maxLogit)
                              {
                                    maxLogit = currentLogit;
                                    tappedClass = c;
                              }
                        }
                  }

                  Debug.Log($"Tapped on class: {tappedClass}. Setting it as the target for painting.");

                  // Set the class index to be painted in the post-process shader
                  classIndexToPaint = tappedClass;
                  postProcessShader.SetInt("classIndexToPaint", classIndexToPaint);
                  postProcessShader.SetInt("classIndexToPaint2", -1); // Reset second class on tap

                  // --- NEW: Communicate with PaintManager ---
                  if (paintManager != null)
                  {
                        // Tell the paint manager which class to paint
                        paintManager.SetTargetClass(tappedClass);

                        // Pass the latest segmentation texture to the paint manager's material
                        paintManager.UpdateSegmentationTexture(segmentationTexture);
                  }
            }
      }

      private IEnumerator ShowClassName(string name)
      {
            if (classNameText != null)
            {
                  classNameText.text = name;
                  classNameText.enabled = true;

                  if (displayNameCoroutine != null)
                  {
                        StopCoroutine(displayNameCoroutine);
                  }
                  displayNameCoroutine = StartCoroutine(HideTextAfterDelay());
            }
            yield break;
      }

      /// <summary>
      /// Hides the class name text after a specified delay.
      /// </summary>
      private IEnumerator HideTextAfterDelay()
      {
            yield return new WaitForSeconds(displayNameDuration);
            if (classNameText != null)
            {
                  classNameText.enabled = false;
            }
            displayNameCoroutine = null;
      }

      private IEnumerator TestMLModelSimple()
      {
            // Create simple gradient test image
            var testTexture = new Texture2D(520, 520, TextureFormat.RGB24, false);
            var pixels = new Color[520 * 520];

            // Simple gradient pattern
            for (int y = 0; y < 520; y++)
            {
                  for (int x = 0; x < 520; x++)
                  {
                        int index = y * 520 + x;
                        float normalizedX = x / 520f;
                        float normalizedY = y / 520f;

                        // Simple color gradient
                        pixels[index] = new Color(normalizedX, normalizedY, 0.5f);
                  }
            }

            testTexture.SetPixels(pixels);
            testTexture.Apply();

            Debug.Log("üé® Created simple gradient test image (520x520)");
            Debug.Log("üî¨ Processing with DeepLabV3+ model...");

            // Process with real ML model
            // This part needs to be adapted to use the new async processing
            // For now, it will just log and not actually process.
            Debug.Log("‚ö†Ô∏è TestMLModelSimple is not fully functional with new async processing.");
            yield return null;

            // Cleanup
            if (testTexture != null)
            {
                  Destroy(testTexture);
            }
      }

      private IEnumerator CreateSimpleTestData()
      {
            // Create even simpler test - just solid colors in blocks
            var testTexture = new Texture2D(520, 520, TextureFormat.RGB24, false);
            var pixels = new Color[520 * 520];

            for (int y = 0; y < 520; y++)
            {
                  for (int x = 0; x < 520; x++)
                  {
                        int index = y * 520 + x;

                        // Create simple blocks of different colors
                        if (x < 260 && y < 260)
                              pixels[index] = Color.red;    // Top-left red
                        else if (x >= 260 && y < 260)
                              pixels[index] = Color.green;  // Top-right green
                        else if (x < 260 && y >= 260)
                              pixels[index] = Color.blue;   // Bottom-left blue
                        else
                              pixels[index] = Color.yellow; // Bottom-right yellow
                  }
            }

            testTexture.SetPixels(pixels);
            testTexture.Apply();

            Debug.Log("üé® Created simple 4-color block test image");
            Debug.Log("üî¨ Sending to model to see what it outputs...");

            // Process and visualize ANY output from model
            // This part needs to be adapted to use the new async processing
            // For now, it will just log and not actually process.
            Debug.Log("‚ö†Ô∏è CreateSimpleTestData is not fully functional with new async processing.");
            yield return null;

            // Cleanup
            if (testTexture != null)
            {
                  Destroy(testTexture);
            }
      }

      /// <summary>
      /// –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ BiSeNet –º–æ–¥–µ–ª—å
      /// </summary>
      [ContextMenu("Switch to BiSeNet Model")]
      private void SwitchToBiSeNetModel()
      {
            Debug.Log("üöÄ Switching to BiSeNet model...");

            // –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ BiSeNet –º–æ–¥–µ–ª—å –≤ Assets/Models/
            var bisetModelPath = "Assets/Models/bisenet-bisenet-float.onnx";
            var bisetModel = UnityEditor.AssetDatabase.LoadAssetAtPath<ModelAsset>(bisetModelPath);

            if (bisetModel != null)
            {
                  modelAsset = bisetModel;

                  // –°–±—Ä–æ—Å–∏–º override resolution –¥–ª—è BiSeNet (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç native 720x960)
                  overrideResolution = Vector2Int.zero;

                  Debug.Log("‚úÖ BiSeNet model loaded successfully!");
                  Debug.Log("üìè Override resolution cleared - using native 720x960");
                  Debug.Log("üîÑ Restart play mode to apply changes.");
            }
            else
            {
                  Debug.LogError("‚ùå BiSeNet model not found at: " + bisetModelPath);
                  Debug.LogError("üìã Make sure bisenet-bisenet-float.onnx is in Assets/Models/ folder");
            }
      }

      /// <summary>
      /// –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ DeepLabV3+ –º–æ–¥–µ–ª—å
      /// </summary>
      [ContextMenu("Switch to DeepLabV3+ Model")]
      private void SwitchToDeepLabModel()
      {
            Debug.Log("üéØ Switching to DeepLabV3+ model...");

            // –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ DeepLabV3+ –º–æ–¥–µ–ª—å –≤ Assets/Models/
            var deeplabModelPath = "Assets/Models/deeplabv3_plus_mobilenet-deeplabv3-plus-mobilenet-float.onnx";
            var deeplabModel = UnityEditor.AssetDatabase.LoadAssetAtPath<ModelAsset>(deeplabModelPath);

            if (deeplabModel != null)
            {
                  modelAsset = deeplabModel;

                  // –°–±—Ä–æ—Å–∏–º override resolution –¥–ª—è DeepLabV3+ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç native 520x520)
                  overrideResolution = Vector2Int.zero;

                  Debug.Log("‚úÖ DeepLabV3+ model loaded successfully!");
                  Debug.Log("üìè Override resolution cleared - using native 520x520");
                  Debug.Log("üîÑ Restart play mode to apply changes.");
            }
            else
            {
                  Debug.LogError("‚ùå DeepLabV3+ model not found at: " + deeplabModelPath);
            }
      }

      /// <summary>
      /// –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ SegFormer –º–æ–¥–µ–ª—å
      /// </summary>
      [ContextMenu("Switch to SegFormer Model")]
      private void SwitchToSegFormerModel()
      {
            Debug.Log("ü§ñ Switching to SegFormer model...");

            // –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ SegFormer –º–æ–¥–µ–ª—å –≤ Assets/Models/
            var segformerModelPath = "Assets/Models/model_fp16.onnx";
            var segformerModel = UnityEditor.AssetDatabase.LoadAssetAtPath<ModelAsset>(segformerModelPath);

            if (segformerModel != null)
            {
                  modelAsset = segformerModel;

                  // –°–±—Ä–æ—Å–∏–º override resolution –¥–ª—è SegFormer (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç native 512x512)
                  overrideResolution = Vector2Int.zero;

                  Debug.Log("‚úÖ SegFormer model loaded successfully!");
                  Debug.Log("üìè Override resolution cleared - using native 512x512");
                  Debug.Log("ü§ñ ADE20K dataset - 150 classes including wall, building, sky, person, etc.");
                  Debug.Log("üîÑ Restart play mode to apply changes.");
            }
            else
            {
                  Debug.LogError("‚ùå SegFormer model not found at: " + segformerModelPath);
                  Debug.LogError("üìã Make sure model_fp16.onnx is in Assets/Models/ folder");
            }
      }

      /// <summary>
      /// –°–±—Ä–æ—Å Override Resolution –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
      /// </summary>
      [ContextMenu("Clear Override Resolution (Use Auto)")]
      private void ClearOverrideResolution()
      {
            overrideResolution = Vector2Int.zero;
            Debug.Log("‚úÖ Override Resolution cleared - will use auto-detection from model");
            Debug.Log("üîÑ Restart play mode to apply changes.");
      }

      /// <summary>
      /// –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ AR Camera Background –∏ camera settings
      /// </summary>
      [ContextMenu("Diagnose Camera Background")]
      private void DiagnoseCameraBackground()
      {
            Debug.Log("üîç === AR CAMERA BACKGROUND –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê ===");

            if (arCameraManager == null)
            {
                  Debug.LogError("‚ùå ARCameraManager –Ω–µ –Ω–∞–π–¥–µ–Ω!");
                  return;
            }

            var camera = arCameraManager.GetComponent<Camera>();
            if (camera == null)
            {
                  Debug.LogError("‚ùå Camera –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω!");
                  return;
            }

            Debug.Log($"üì∑ Camera ClearFlags: {camera.clearFlags}");
            Debug.Log($"üé® Camera BackgroundColor: {camera.backgroundColor}");

            var arCameraBackground = arCameraManager.GetComponent<UnityEngine.XR.ARFoundation.ARCameraBackground>();
            if (arCameraBackground == null)
            {
                  Debug.LogError("‚ùå ARCameraBackground –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –ù–ï –ù–ê–ô–î–ï–ù! –≠—Ç–æ –ø—Ä–∏—á–∏–Ω–∞ —á–µ—Ä–Ω–æ–≥–æ —ç–∫—Ä–∞–Ω–∞!");
                  Debug.LogError("üö® –†–ï–®–ï–ù–ò–ï: –î–æ–±–∞–≤—å—Ç–µ ARCameraBackground –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –Ω–∞ AR Camera!");
                  return;
            }

            Debug.Log($"‚úÖ ARCameraBackground –Ω–∞–π–¥–µ–Ω, enabled: {arCameraBackground.enabled}");
            Debug.Log($"üì± Custom material: {arCameraBackground.customMaterial}");

            // –ü–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –≤–∫–ª—é—á–∏—Ç—å ARCameraBackground
            if (!arCameraBackground.enabled)
            {
                  Debug.LogWarning("‚ö†Ô∏è ARCameraBackground –æ—Ç–∫–ª—é—á–µ–Ω! –í–∫–ª—é—á–∞–µ–º...");
                  arCameraBackground.enabled = true;
            }

            // –ü—Ä–æ–≤–µ—Ä–∏–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞–º–µ—Ä—ã
            if (camera.clearFlags == CameraClearFlags.SolidColor)
            {
                  Debug.LogWarning("‚ö†Ô∏è Camera ClearFlags = SolidColor (—á–µ—Ä–Ω—ã–π —ç–∫—Ä–∞–Ω). ARCameraBackground –¥–æ–ª–∂–µ–Ω —ç—Ç–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å.");
                  // ARCameraBackground –¥–æ–ª–∂–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑–º–µ–Ω–∏—Ç—å clearFlags –Ω–∞ Color
            }

            // –ü—Ä–æ–≤–µ—Ä–∏–º AR Session
            var arSession = FindObjectOfType<UnityEngine.XR.ARFoundation.ARSession>();
            if (arSession == null)
            {
                  Debug.LogError("‚ùå ARSession –Ω–µ –Ω–∞–π–¥–µ–Ω!");
                  return;
            }

            Debug.Log($"üéØ ARSession state: {UnityEngine.XR.ARFoundation.ARSession.state}");
            Debug.Log($"üì° ARSession enabled: {arSession.enabled}");

            // –î–µ—Ç–∞–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è AR Session
            var sessionState = UnityEngine.XR.ARFoundation.ARSession.state;
            switch (sessionState)
            {
                  case UnityEngine.XR.ARFoundation.ARSessionState.CheckingAvailability:
                        Debug.LogWarning("‚è≥ AR –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å. –ü–æ–¥–æ–∂–¥–∏—Ç–µ...");
                        break;
                  case UnityEngine.XR.ARFoundation.ARSessionState.Installing:
                        Debug.LogWarning("üì¶ AR —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è. –ü–æ–¥–æ–∂–¥–∏—Ç–µ...");
                        break;
                  case UnityEngine.XR.ARFoundation.ARSessionState.Ready:
                        Debug.Log("‚úÖ AR –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!");
                        break;
                  case UnityEngine.XR.ARFoundation.ARSessionState.SessionInitializing:
                        Debug.LogWarning("üîÑ AR –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è...");
                        break;
                  case UnityEngine.XR.ARFoundation.ARSessionState.SessionTracking:
                        Debug.Log("üéØ AR –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –æ–∫—Ä—É–∂–µ–Ω–∏–µ!");
                        break;
                  case UnityEngine.XR.ARFoundation.ARSessionState.Unsupported:
                        Debug.LogError("‚ùå AR –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –Ω–∞ —ç—Ç–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ!");
                        break;
                  case UnityEngine.XR.ARFoundation.ARSessionState.NeedsInstall:
                        Debug.LogError("üì± –¢—Ä–µ–±—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ AR –ø–∞–∫–µ—Ç–æ–≤!");
                        break;
                  default:
                        Debug.LogWarning($"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ AR: {sessionState}");
                        break;
            }

            // –ü—Ä–æ–≤–µ—Ä–∏–º –µ—Å—Ç—å –ª–∏ camera frame data
            if (arCameraManager.TryAcquireLatestCpuImage(out var image))
            {
                  Debug.Log($"‚úÖ Camera frame –¥–æ—Å—Ç—É–ø–µ–Ω: {image.width}x{image.height}, format: {image.format}");
                  image.Dispose();
            }
            else
            {
                  Debug.LogWarning("‚ö†Ô∏è Camera frame –ù–ï –î–û–°–¢–£–ü–ï–ù! AR –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.");
            }
      }

      [ContextMenu("Toggle Horizontal Mirror")]
      private void ToggleHorizontalMirror()
      {
            mirrorX = !mirrorX;
            Debug.Log($"‚úÖ Horizontal mirror (transformation) set to: {mirrorX}. Restart play mode to apply changes.");
      }

      [ContextMenu("Toggle Vertical Mirror")]
      private void ToggleVerticalMirror()
      {
            mirrorY = !mirrorY;
            Debug.Log($"‚úÖ Vertical mirror (transformation) set to: {mirrorY}. Restart play mode to apply changes.");
      }

      [ContextMenu("Test All Mirror Combinations")]
      private void TestAllMirrorCombinations()
      {
            Debug.Log("üîÑ Testing all mirror combinations:");
            Debug.Log($"   Current: MirrorX={mirrorX}, MirrorY={mirrorY}");
            Debug.Log($"   Try: MirrorX=true, MirrorY=true (both mirrors)");
            Debug.Log($"   Try: MirrorX=false, MirrorY=true (only vertical)");
            Debug.Log($"   Try: MirrorX=true, MirrorY=false (only horizontal)");
            Debug.Log($"   Try: MirrorX=false, MirrorY=false (no mirrors)");
            Debug.Log("üí° Change values in inspector and restart play mode to test each combination.");
      }

      [ContextMenu("Diagnose Vertical Lines")]
      private void DiagnoseVerticalLines()
      {
            // This method needs to be adapted to read from the latest processed data
            // For now, it will just log a warning.
            Debug.LogWarning("‚ö†Ô∏è DiagnoseVerticalLines is not fully functional with new async processing.");
      }
}
