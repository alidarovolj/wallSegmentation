План модификации ARWallPresenter для фотореалистичной окраски стен в ARРаздел 1: Архитектурный анализ и стратегия интеграцииДанный раздел закладывает техническую основу, анализируя существующую структуру проекта и определяя высокоуровневый подход к интеграции новой функциональности фотореалистичного рендеринга.1.1 Предполагаемый конвейер данных в проекте wallSegmentationДля разработки эффективного плана модификации необходимо сначала сформулировать предположения о текущей архитектуре проекта wallSegmentation. Исходя из названий компонентов (AsyncSegmentationManager, WallSegmentation, ARWallPresenter), можно реконструировать наиболее вероятный конвейер обработки данных:AsyncSegmentationManager: Этот компонент, вероятно, является отправной точкой конвейера. Он отвечает за выполнение основной ресурсоемкой задачи — семантической сегментации. В асинхронном режиме, чтобы не блокировать основной поток выполнения, он получает видеопоток с камеры устройства и обрабатывает его с помощью предварительно обученной модели машинного обучения (например, сверточной нейронной сети, CNN). Результатом работы этого менеджера является необработанная маска сегментации, где пиксели, идентифицированные как принадлежащие стенам, имеют определенное значение.WallSegmentation: Этот компонент, скорее всего, выступает в роли промежуточного обработчика. Он принимает сырую маску от AsyncSegmentationManager и выполняет ее постобработку. Это может включать в себя фильтрацию шума, сглаживание краев маски с использованием морфологических операций или размытия по Гауссу, а также преобразование данных в формат, удобный для рендеринга. Конечным продуктом этого этапа, вероятно, является текстура маски (Texture2D), где, например, в альфа-канале закодирована принадлежность пикселя к стене.ARWallPresenter: В текущей архитектуре этот компонент является терминальным узлом конвейера, ответственным исключительно за визуализацию результата. Можно предположить, что его текущая реализация довольно проста: он либо рендерит полупрозрачный полигон (mesh), геометрия которого соответствует обнаруженным стенам, либо, что более вероятно для простоты, отображает полноэкранный прямоугольник (quad) с материалом, использующим базовый шейдер. Этот шейдер применяет сплошной цвет и использует текстуру маски от WallSegmentation для определения прозрачности. Такой подход приводит к тому, что цвет просто накладывается поверх изображения с камеры, полностью скрывая оригинальную текстуру стены, ее освещение, тени и блики.1.2 Модификация ARWallPresenter для фотореалистичного рендеринга в реальном времениДля достижения цели фотореалистичной окраски ARWallPresenter должен быть кардинально переработан. Его роль трансформируется из простого визуализатора в сложный контроллер рендеринга, который управляет взаимодействием между данными реального мира и виртуальным цветом.Обновленный ARWallPresenter будет нести следующие ключевые обязанности:Управление материалом: Компонент будет отвечать за создание и управление экземпляром Material, который использует новый, специально разработанный шейдер для фотореалистичной окраски. Это гарантирует, что изменения, вносимые в материал (например, смена цвета), не затронут другие объекты в сцене.Распространение данных в шейдер: В каждом кадре, в методе Update(), ARWallPresenter будет собирать все необходимые данные и передавать их в шейдер через методы Material.SetFloat(), Material.SetColor(), Material.SetTexture() и т.д. К этим данным относятся:Выбранный пользователем цвет краски (полученный из UI).Актуальная текстура маски сегментации стен.Все релевантные данные об освещении окружения, полученные от ARCameraManager (подробно рассмотрено в Разделе 2).Управление геометрией: ARWallPresenter продолжит управлять геометрией, на которую накладывается материал. В большинстве случаев это будет простой полноэкранный прямоугольник, так как эффект должен применяться ко всему экрану, а видимость будет контролироваться маской на уровне пиксельного шейдера.1.3 Ключевая задача рендеринга: смешивание цвета с сохранением реальностиФундаментальное изменение в подходе заключается в переходе от наложения (overlaying) цвета к его смешиванию (blending) с живым видеопотоком. Это является краеугольным камнем для достижения фотореализма, так как именно смешивание позволяет сохранить все детали физической стены: ее текстуру, фактуру, трещины, а также все нюансы реального освещения, включая мягкие тени от объектов в комнате и блики от источников света.Чтобы реализовать такое смешивание, пиксельный шейдер должен иметь доступ к цвету пикселей сцены, которые находятся за геометрией, на которую он накладывается. Эта задача решается с помощью специфических для каждого конвейера рендеринга техник:Universal Render Pipeline (URP): В URP для этой цели используется нода Scene Color в Shader Graph или текстура _CameraOpaqueTexture при написании шейдера на HLSL. Для ее активации необходимо в настройках используемого URP Asset включить опцию "Opaque Texture". Это указывает конвейеру на необходимость сохранять копию отрендеренной сцены перед началом рендеринга прозрачных объектов.Built-in Render Pipeline: В стандартном конвейере рендеринга используется команда GrabPass { } в ShaderLab. Эта команда явно указывает GPU сделать снимок текущего содержимого кадрового буфера и сохранить его в текстуру. Эта текстура затем становится доступной для сэмплирования в последующих проходах шейдера.Выбор этой техники является основополагающим для всего визуального эффекта. Он переводит задачу из области простой альфа-прозрачности в область сложных попиксельных операций смешивания, что напрямую влияет на архитектуру и производительность.1.4 Последствия для архитектурыНаиболее значимым архитектурным изменением является введение зависимости от копирования полноэкранного буфера (Scene Color или GrabPass). Это решение имеет глубокие и неизбежные последствия для производительности.Процесс принятия этого решения выглядит следующим образом:Требование пользователя — сохранить текстуру и освещение реальной стены.Это означает, что итоговый цвет пикселя на экране должен быть результатом математической операции между желаемым цветом краски и цветом реальной стены, видимым камерой.Следовательно, шейдер на каждом пикселе должен иметь два входных значения: цвет краски и цвет пикселя с камеры.Единственный способ для шейдера "прочитать" то, что находится позади него — это получить текстуру уже отрендеренной на данный момент сцены.Именно эту функциональность предоставляют Scene Color в URP и GrabPass в Built-in.Вывод: Данная операция является дорогостоящей. Она требует дополнительной пропускной способности памяти для копирования полноэкранной текстуры и может вызывать задержки в конвейере рендеринга GPU (pipeline stall). Однако эта стоимость является не подлежащей обсуждению "ценой входа" для достижения требуемого визуального эффекта. Таким образом, все последующие усилия по оптимизации должны быть сосредоточены на минимизации сложности самого шейдера смешивания, поскольку затраты на захват сцены являются фиксированными. Это архитектурное решение немедленно переводит вопрос производительности с уровня отдельной функции на уровень системного приоритета, определяя дальнейшую стратегию разработки и оптимизации.Раздел 2: Динамическое освещение окружения с помощью AR FoundationВ этом разделе подробно рассматривается процесс получения и использования данных о реальном освещении, что является критически важным для того, чтобы виртуальный цвет краски реалистично реагировал на изменения в окружающей среде.2.1 Конфигурация и получение данных из ARCameraManagerДля того чтобы виртуальные объекты или эффекты выглядели как часть реального мира, они должны быть освещены так же, как и реальные объекты. AR Foundation предоставляет API для оценки параметров освещения в реальном времени.Активация Light Estimation: В редакторе Unity необходимо выбрать объект AR-камеры в иерархии сцены. В инспекторе, на компоненте AR Camera Manager, следует установить флажок "Light Estimation".Выбор режимов: ARCore и ARKit предлагают различные уровни детализации оценки освещения. Для достижения максимального фотореализма следует ориентироваться на режим "Environmental HDR". Этот режим, при поддержке устройством, предоставляет наиболее полный набор данных, включая направление и интенсивность основного источника света, а также сферические гармоники для окружающего освещения.1 Режим "Ambient Intensity" является менее детализированным, но более широко поддерживаемым запасным вариантом, предоставляющим только общую яркость и цвет.Подписка на событие frameReceived: Модифицированный скрипт ARWallPresenter должен подписаться на событие ARCameraManager.frameReceived. Это событие вызывается каждый кадр, когда обновляются данные AR-трекинга, и предоставляет доступ к структуре ARLightEstimationData, содержащей все оцененные параметры освещения.2Пример реализации подписки в ARWallPresenter.cs 2:C#using UnityEngine;
using UnityEngine.XR.ARFoundation;

public class ARWallPresenter : MonoBehaviour
{
   
    private ARCameraManager arCameraManager;
   
    private Material wallMaterial; // Материал для окраски стен

    void OnEnable()
    {
        if (arCameraManager!= null)
        {
            arCameraManager.frameReceived += OnFrameReceived;
        }
    }

    void OnDisable()
    {
        if (arCameraManager!= null)
        {
            arCameraManager.frameReceived -= OnFrameReceived;
        }
    }

    void OnFrameReceived(ARCameraFrameEventArgs eventArgs)
    {
        if (wallMaterial == null) return;

        var lightEstimation = eventArgs.lightEstimation;

        // Передача основных параметров освещения в шейдер
        if (lightEstimation.averageBrightness.HasValue)
        {
            wallMaterial.SetFloat("_GlobalBrightness", lightEstimation.averageBrightness.Value);
        }

        if (lightEstimation.mainLightColor.HasValue)
        {
            // mainLightColor часто бывает слишком насыщенным, может потребоваться коррекция
            wallMaterial.SetColor("_RealWorldLightColor", lightEstimation.mainLightColor.Value);
        }
        else if (lightEstimation.colorCorrection.HasValue)
        {
            // В качестве запасного варианта используем colorCorrection
            wallMaterial.SetColor("_RealWorldLightColor", lightEstimation.colorCorrection.Value);
        }

        if (lightEstimation.mainLightDirection.HasValue)
        {
            wallMaterial.SetVector("_RealWorldLightDir", lightEstimation.mainLightDirection.Value);
        }

        // Более продвинутая техника с использованием сферических гармоник
        if (lightEstimation.ambientSphericalHarmonics.HasValue)
        {
            // Сферические гармоники передаются в шейдер как массив Vector4
            // Unity предоставляет удобные методы для их передачи
            // RenderSettings.ambientProbe = lightEstimation.ambientSphericalHarmonics.Value;
            // Или передача напрямую в шейдер для кастомного расчета
        }
    }
}
2.2 Передача данных о реальном освещении на GPUДанные, извлеченные из ARLightEstimationData, должны передаваться в шейдер материала стены каждый кадр. Простое применение этих данных к стандартному компоненту Light в Unity является недостаточным для данной задачи. Причина в том, что стандартный свет влияет на объекты в соответствии с их PBR-свойствами (metallic, smoothness), в то время как наша цель — заставить сам цвет краски выглядеть так, как будто он освещен реальным миром.Это требует выполнения операции "предварительного освещения" (pre-lighting) цвета краски непосредственно внутри шейдера. Логика шейдера должна использовать полученные данные для модуляции базового цвета краски перед его смешиванием с изображением с камеры.Свойства основного света: Параметры, такие как averageBrightness, averageColorTemperature, mainLightDirection и mainLightColor, являются наиболее важными для имитации прямого освещения. Они передаются в шейдер как uniform-переменные, например, _GlobalBrightness, _RealWorldLightColor, _RealWorldLightDir.Окружающее освещение (Ambient): Параметр ambientSphericalHarmonics предоставляет гораздо более точное и всестороннее представление об окружающем освещении в сцене по сравнению с простым цветом. Сферические гармоники L2 — это набор коэффициентов, которые описывают распределение света низкой частоты со всех направлений. В шейдере их можно использовать для расчета рассеянного (diffuse) освещения, которое падает на поверхность в зависимости от ее нормали. Это позволяет цвету краски правильно реагировать на свет, отраженный от других объектов в реальной комнате, что значительно повышает реализм. Их можно либо установить глобально через RenderSettings.ambientProbe, либо передать напрямую в шейдер для более контролируемого использования.Тесная связь между кодом на C#, собирающим данные об освещении, и логикой шейдера на HLSL означает, что они должны разрабатываться совместно. ARWallPresenter и шейдер стены функционируют как две половины единой системы. Любое изменение в наборе данных, передаваемых из C#, требует соответствующего изменения в uniform-переменных и логике шейдера.2.3 Таблица 2.1: Анализ параметров Light Estimation из AR FoundationДанная таблица служит справочным руководством для команды разработки, разъясняя назначение каждого параметра, его доступность на платформах и предполагаемое использование в шейдере.Имя параметра (ARLightEstimationData)Тип данныхОписаниеОсновное использование в шейдереТипичная поддержка платформaverageBrightnessfloat?Средняя яркость сцены, нормализованная в диапазоне .Модуляция общей интенсивности цвета краски. Используется как множитель для _PaintColor.Базовая (ARKit/ARCore).averageColorTemperaturefloat?Оцененная цветовая температура в Кельвинах.Коррекция цветового баланса краски для соответствия теплому или холодному освещению.Базовая (ARKit/ARCore).colorCorrectionColor?Коэффициенты коррекции для каналов RGB для баланса белого.Модуляция цвета краски для соответствия общему цветовому тону сцены.Базовая (ARKit/ARCore).mainLightDirectionVector3?Нормализованный вектор, указывающий направление основного источника света.Определение направления для расчета бликов (specular) на поверхности краски.Environmental HDR (ARKit/ARCore).mainLightIntensityLumens / mainLightColorfloat? / Color?Интенсивность (в люменах) и цвет основного источника света.Используется для расчета прямого освещения и бликов на краске.Environmental HDR (ARKit/ARCore).ambientSphericalHarmonicsSphericalHarmonicsL2?Коэффициенты сферических гармоник, представляющие окружающее освещение.Расчет рассеянного (diffuse) окружающего света на краске с учетом нормали поверхности.Environmental HDR (ARKit/ARCore).Раздел 3: Реализация шейдера для высококачественного смешиванияЭтот раздел является техническим ядром отчета. В нем подробно рассматривается математика и практическая реализация шейдера, который создает конечный фотореалистичный эффект окраски стен.3.1 Математическая основа: сравнительный анализ режимов смешиванияФотореалистичное наложение цвета требует выбора такого режима смешивания, который сохраняет детали яркости (светов и теней) нижележащего слоя (изображения с камеры), изменяя при этом только его цветовой оттенок. Рассмотрим основные режимы смешивания и их математические формулы, где все значения цвета нормализованы в диапазон .Multiply (Умножение):Формула: Result=Base×BlendАнализ: Этот режим всегда затемняет изображение, за исключением случаев смешивания с белым цветом (Blend=1). Он хорошо сохраняет тени, но полностью "сжигает" (clipping) света, превращая их в цвет наложения. Не подходит для нашей задачи, так как уничтожает информацию о бликах и светлых участках стены.Screen (Экран):Формула: Result=1−(1−Base)×(1−Blend)Анализ: Этот режим является инверсией Multiply и всегда осветляет изображение, за исключением смешивания с черным цветом (Blend=0). Он хорошо сохраняет блики, но "размывает" тени, делая их блеклыми. Также не подходит, так как теряется информация о темных участках и тенях.Overlay (Перекрытие):Формула: Это условная комбинация режимов Multiply и Screen, зависящая от яркости базового слоя.Result={2×Base×Blend,1−2×(1−Base)×(1−Blend),​if Base<0.5if Base≥0.5​Анализ: Когда базовый цвет (Base) темнее 50% серого, применяется режим, схожий с Multiply, затемняя темные участки. Когда базовый цвет светлее, применяется режим, схожий с Screen, осветляя светлые участки. Этот двойственный характер позволяет увеличить контраст, накладывая цвет Blend таким образом, что он сохраняет как тени, так и света базового изображения. Это идеальный кандидат для нашей задачи.3.2 Таблица 3.1: Сравнение режимов смешивания для окраски стенДанная таблица предоставляет наглядное обоснование выбора режима Overlay по сравнению с другими кандидатами.Режим смешиванияВлияние на тениВлияние на светаСохранение текстурыПригодность (1-5)ОбоснованиеAlpha BlendСкрыты (закрашены)Скрыты (закрашены)Нет1Простая прозрачность, полностью скрывает детали стены. Непригоден.MultiplyСохранены, но затемненыУничтожены (закрашены)Частично2Теряется вся информация о бликах и светлых участках. Не фотореалистично.ScreenУничтожены (выбелены)Сохранены, но осветленыЧастично2Теряется вся информация о тенях и темных участках. Не фотореалистично.OverlayСохранены и усиленыСохранены и усиленыДа5Идеально подходит. Сохраняет весь тональный диапазон стены, усиливая контраст и реалистично накладывая цвет.3.3 Шейдер смешивания Overlay: основная логика и реализацияШейдер должен быть создан как Unlit (неосвещенный), поскольку все расчеты освещения производятся вручную на основе данных от AR Foundation. Он должен работать в режиме Transparent.Входные данные (Uniform-переменные):sampler2D _CameraOpaqueTexture или _GrabTexture: Текстура с изображением сцены.sampler2D _SegmentationMask: Одноканальная текстура с маской стен.float4 _PaintColor: Базовый цвет краски, выбранный пользователем (в линейном цветовом пространстве).float4 _RealWorldLightColor: Цвет основного источника света из AR-данных.float _GlobalBrightness: Общая яркость сцены из AR-данных.float _EdgeSoftness: Параметр для управления мягкостью краев маски.Логика фрагментного шейдера (HLSL):High-level shader language// В блоке Pass
// Для URP требуется тег "RenderPipeline" = "UniversalPipeline"
// Для Built-in требуется GrabPass {}

// Внутри HLSLPROGRAM
half4 frag(Varyings IN) : SV_Target
{
    // 1. Сэмплируем маску сегментации
    // Предполагаем, что маска в альфа-канале
    half maskValue = tex2D(_SegmentationMask, IN.uv).a;

    // 2. Отбрасываем пиксели, которые точно не являются стеной
    // clip() эффективнее, чем if-discard, на многих GPU
    clip(maskValue - 0.01);

    // 3. Сэмплируем цвет сцены (стены)
    // Для GrabPass UV могут быть такими же, как у IN.uv
    // Для _CameraOpaqueTexture требуются экранные координаты
    float4 screenPos = IN.positionHCS / IN.positionHCS.w;
    float2 screenUV = screenPos.xy;
    #if UNITY_UV_STARTS_AT_TOP
        screenUV.y = 1 - screenUV.y;
    #endif
    half4 baseColor = tex2D(_CameraOpaqueTexture, screenUV);

    // 4. "Освещаем" виртуальный цвет краски
    half3 litPaintColor = _PaintColor.rgb * _RealWorldLightColor.rgb * _GlobalBrightness;

    // 5. Применяем формулу Overlay
    half3 overlayResult;
    // Условие if можно заменить на step() для оптимизации
    half3 condition = step(0.5, baseColor.rgb);
    // Формула для base >= 0.5 (Screen)
    half3 screenBlend = 1.0 - 2.0 * (1.0 - baseColor.rgb) * (1.0 - litPaintColor);
    // Формула для base < 0.5 (Multiply)
    half3 multiplyBlend = 2.0 * baseColor.rgb * litPaintColor;
    // Выбираем результат без ветвления
    overlayResult = lerp(multiplyBlend, screenBlend, condition);
    
    // 6. Рассчитываем итоговую альфу с мягкими краями
    half finalAlpha = smoothstep(0.1, 0.1 + _EdgeSoftness, maskValue);

    return half4(overlayResult, finalAlpha);
}
3.4 Продвинутое сглаживание краев для бесшовной интеграцииБинарный характер масок сегментации создает резкие, "зубчатые" и неестественные края. Смягчение этих краев является критически важным шагом для достижения визуальной достоверности.Метод 1: smoothstep (Хорошо)Функция smoothstep(edge0, edge1, x) выполняет гладкую эрмитову интерполяцию между 0 и 1, когда x находится между edge0 и edge1. Мы можем использовать значение маски maskValue в качестве x.float alpha = smoothstep(0.1, 0.1 + _EdgeSoftness, maskValue);Преимущества: Простота реализации, хороший визуальный результат.Недостатки: Ширина сглаживания (_EdgeSoftness) задана в пространстве UV-координат маски. Это означает, что при приближении камеры к стене край будет выглядеть очень размытым, а при удалении — снова станет резким. Эффект не адаптируется к разрешению экрана.Метод 2: Экранные производные (Screen-Space Derivatives) (Лучше/Продвинутый)Эта техника позволяет создавать идеально сглаженные (anti-aliased) края, которые адаптируются к разрешению экрана и углу обзора, создавая стабильно мягкий переход шириной примерно в один пиксель.Функции ddx(p), ddy(p) вычисляют частную производную параметра p по осям X и Y экрана. Функция fwidth(p) эквивалентна abs(ddx(p)) + abs(ddy(p)) и показывает, насколько сильно значение p изменяется между соседними пикселями.Логика:Вычисляем fwidth(maskValue). Это значение говорит нам, насколько сильно меняется маска на границе одного пикселя. Фактически, это ширина края маски в экранном пространстве.Используем эту ширину для динамического контроля диапазона smoothstep.float edgeWidth = fwidth(maskValue) * 1.0; // Множитель для контроля мягкостиfloat alpha = smoothstep(0.5 - edgeWidth, 0.5 + edgeWidth, maskValue);Преимущества: Создает идеально четкий, но сглаженный край толщиной в один пиксель независимо от расстояния до объекта, угла обзора или разрешения экрана. Это является золотым стандартом для процедурного анти-алиасинга.Недостатки: Требует более глубокого понимания работы GPU; может быть не поддерживаема на очень старых мобильных устройствах (хотя современные устройства с поддержкой OpenGL ES 3.0+ и Vulkan ее поддерживают).Для проекта, ставящего в приоритет "фотореализм", рекомендуется использовать продвинутый метод на основе экранных производных. Он демонстрирует более глубокое понимание рендеринга на GPU и напрямую способствует созданию более качественного и профессионального конечного продукта.Раздел 4: Сравнительный анализ рабочих процессов создания шейдеровВ этом разделе дается стратегическая рекомендация по процессу разработки, используя сильные стороны как визуальных, так и кодовых инструментов создания шейдеров.4.1 Быстрое прототипирование и визуальная проверка с помощью Shader GraphСильные стороны: Shader Graph является идеальным инструментом для начального этапа реализации. Его нодовый интерфейс позволяет быстро итерировать и получать немедленную визуальную обратную связь, что бесценно для такого сложного визуального эффекта.Шаги прототипирования в Shader Graph:Создать новый Unlit Shader Graph для URP. В настройках графа установить тип поверхности (Surface) на Transparent.Использовать ноду Scene Color для получения базового цвета Base.Создать свойство Texture2D для _SegmentationMask.Создать свойства Vector4 и Float для _PaintColor, _RealWorldLightColor и _GlobalBrightness.Реализовать предварительное освещение цвета краски с помощью нод Multiply.Использовать ноду Blend и установить ее режим (Mode) на Overlay.Реализовать сглаживание краев с помощью ноды Smoothstep.Подключить итоговый цвет к выходу Base Color мастер-ноды, а рассчитанную альфу — к выходу Alpha.Этот подход позволяет художникам и техническим художникам принимать активное участие в настройке внешнего вида эффекта без необходимости глубокого погружения в код.4.2 Финальная реализация и оптимизация с помощью HLSLСильные стороны: Написание шейдера вручную на HLSL (High-Level Shading Language) обеспечивает максимальную производительность и контроль, что критически важно для мобильных платформ.Причины для перехода на HLSL для производственной версии:Производительность: Shader Graph, будучи инструментом общего назначения, может генерировать избыточный или неоптимальный код. Опытный программист может написать более эффективный HLSL-код, используя такие приемы, как объединение математических операций (например, использование инструкции mad — multiply-add), ручное управление точностью вычислений (half вместо float для цветов), и минимизация количества сэмплов текстур.Контроль: Некоторые продвинутые техники, такие как сложное использование экранных производных или операции с буфером трафарета (stencil buffer), проще реализовать или доступны только в "сыром" HLSL.Читаемость и поддержка: Для опытных графических программистов хорошо структурированный HLSL-код часто легче читать, отлаживать и контролировать в системах контроля версий (например, Git), чем большую и запутанную схему из нод.Избегание "черных ящиков": Нода Blend в Shader Graph удобна, но скрывает под собой конкретную реализацию. Написание этой логики на HLSL гарантирует, что разработчик точно понимает и контролирует выполняемую формулу. Документация Unity даже предоставляет исходный код этих функций, который можно скопировать и оптимизировать.4.3 Рекомендуемый гибридный рабочий процессНастоятельно рекомендуется двухэтапный подход, сочетающий сильные стороны обоих методов:Фаза 1: Прототипирование (Shader Graph): Использовать Shader Graph для создания и визуального совершенствования всего эффекта. Это "художественная" фаза, где определяется внешний вид, настраиваются цвета, интенсивность и общая эстетика.Фаза 2: Оптимизация (HLSL): После утверждения визуального результата создать новый, написанный вручную HLSL-шейдер. Можно использовать функцию "View Generated Code" в Shader Graph в качестве отправной точки или справочного материала, но цель — переписать логику чисто и эффективно, применяя все принципы мобильной оптимизации (рассмотрено в Разделе 5). Это "инженерная" фаза, где достигается максимальная производительность.4.4 Таблица 4.1: Сравнение подходов к реализации шейдераДанная таблица наглядно представляет компромиссы между Shader Graph и HLSL, обосновывая рекомендуемый гибридный подход.КритерийShader GraphРучной HLSLГибридный подходСкорость разработкиВысокаяНизкаяОптимальная (быстрый старт, затем оптимизация)Простота итерацийВысокаяНизкаяВысокая на начальном этапеКонтроль производительностиНизкийВысокийВысокий (в финальной версии)Доступ к продвинутым функциямСреднийВысокийВысокийПонятность для художниковВысокаяНизкаяПозволяет художникам работать на этапе прототипаПонятность для программистовНизкая (для сложных графов)Высокая (для чистого кода)Высокая (в финальной версии)Итоговая производительностьХорошаяОтличнаяОтличнаяРаздел 5: Кроссплатформенная производительность и оптимизация энергопотребленияЭтот раздел посвящен критически важному нефункциональному требованию: обеспечению высокой производительности приложения на мобильных устройствах среднего класса без чрезмерного расхода заряда батареи.5.1 Анализ стоимости рендеринга в реальном времениДанная функциональность будет в подавляющем большинстве случаев ограничена производительностью фрагментного (пиксельного) шейдера. Стоимость будет напрямую масштабироваться с разрешением экрана.Основные центры затрат производительности:Копирование буфера сцены (Scene Color/GrabPass): Как было определено в Разделе 1.4, это наиболее значительная фиксированная стоимость. Эта операция потребляет пропускную способность памяти GPU и может приводить к простоям в конвейере рендеринга. Ее нельзя избежать, но можно минимизировать ее влияние, максимально упростив все, что рендерится после нее.Перерисовка (Overdraw): Эффект является полноэкранным. Это означает, что для каждого пикселя, покрытого маской стены, будет выполнен сложный фрагментный шейдер. Возможности для ранней отсечки по глубине (early Z-culling) отсутствуют, так как мы рендерим прозрачный полноэкранный прямоугольник поверх уже готовой сцены.Количество инструкций шейдера: Количество арифметических операций и выборок из текстур (tex2D) во фрагментном шейдере является основной переменной стоимостью. Каждая операция сложения, умножения или сэмплирования текстуры увеличивает нагрузку на GPU и, как следствие, энергопотребление.5.2 Технический чек-лист по оптимизации мобильных AR-шейдеровЭтот чек-лист представляет собой набор практических шагов для фазы оптимизации, основанный на лучших практиках мобильной разработки.3Точность вычислений (Precision):Использовать half (16-битная точность) для цветов, UV-координат и других значений, не требующих высокой точности. float (32-битная точность) следует использовать только для позиционных данных или сложных математических расчетов, где важна точность. Это снижает нагрузку на регистры GPU и экономит пропускную способность памяти.Оптимизация вычислений:Переносить как можно больше вычислений из фрагментного шейдера в вершинный.4 Вершинный шейдер выполняется для каждой вершины геометрии, а фрагментный — для каждого пикселя. Для полноэкранного прямоугольника вершин будет всего 4, а пикселей — миллионы.Предварительно вычислять значения на CPU. Например, итоговый "освещенный" цвет краски (litPaintColor) можно частично или полностью рассчитать на C# и передать в шейдер как одну uniform-переменную.Избегать условных ветвлений (if/else) в шейдерах. Вместо них следует использовать встроенные функции, такие как step, lerp, smoothstep, которые компилируются в безынструкционный код на большинстве архитектур GPU.Оптимизация текстур:Убедиться, что текстура маски сегментации использует наиболее эффективный формат. Если она одноканальная, можно использовать формат R8.Отключить генерацию mip-уровней для текстур, которые не требуют масштабирования, таких как маска сегментации, отображаемая 1:1 с экраном.3Использовать современные форматы сжатия текстур, такие как ASTC, для любых других задействованных текстур.3Общие практики:Профилировать приложение с самого начала и на регулярной основе с помощью Unity Profiler и Frame Debugger.Отключить ненужные функции на самом материале, такие как отбрасывание теней (Cast Shadows), так как эффект является неосвещенным (Unlit).45.3 Таблица 5.1: Чек-лист по оптимизации производительности на мобильных устройствахЭта таблица предоставляет структурированный и действенный список задач по оптимизации для команды разработки.КатегорияТактика оптимизацииОбоснованиеСтатусТочностьИспользовать half для цветов и UVСнижает потребление памяти и нагрузку на ALU GPU.☐ВычисленияПеренести расчет litPaintColor на CPUФрагментный шейдер выполняется для каждого пикселя, CPU - один раз за кадр.☐ВычисленияЗаменить if на step()/lerp()Избегание ветвлений в коде GPU, которые могут быть дорогостоящими.☐ТекстурыИспользовать tex2Dlod вместо tex2D при необходимостиВ некоторых случаях позволяет избежать неявных вычислений производных.☐ТекстурыОтключить Mipmaps для маски сегментацииМаска не масштабируется, mip-уровни не нужны и тратят память.☐ТекстурыИспользовать формат R8 для одноканальной маскиЭкономия памяти текстуры (8 бит на пиксель вместо 32 для RGBA32).☐ПрофилированиеАнализ времени выполнения шейдера в Unity ProfilerИдентификация "горячих точек" и самых дорогих операций в шейдере.☐ПрофилированиеИспользование Frame DebuggerВизуальная проверка конвейера рендеринга, подтверждение отсутствия лишних проходов.☐5.4 Стратегия профилирования и бенчмаркинга на целевых устройствахОпределение целевых устройств: Выбрать несколько репрезентативных устройств среднего класса (например, iPhone 12, Samsung Galaxy S20) для тестирования.Базовые метрики: Замерить производительность (FPS, время на кадр в мс) с отключенной функцией окраски стен для получения базового уровня.Измерение влияния: Включить функцию и замерить падение производительности в контролируемых условиях (одна и та же сцена, освещение).Глубокий анализ: Использовать GPU-модуль Unity Profiler для анализа вызовов отрисовки (draw calls) и стоимости выполнения шейдера.Отладка: Использовать Frame Debugger для пошагового анализа кадра и подтверждения, что проход Scene Color и проход рендеринга стены выполняются корректно и в правильном порядке.Долгосрочное тестирование: Мониторить расход заряда батареи и нагрев устройства при непрерывном использовании функции в течение 5-10 минут.Раздел 6: Итоговые рекомендации и дорожная карта реализацииЭтот заключительный раздел обобщает проведенный анализ и представляет четкий, стратегический план действий для команды разработки.6.1 Краткое изложение рекомендуемого технического подходаДля успешной реализации фотореалистичной окраски стен в проекте wallSegmentation рекомендуется следующий комплексный подход:Архитектура: Переработать ARWallPresenter в контроллер рендеринга, который управляет кастомным материалом и передает в его шейдер данные об освещении и цвете в каждом кадре.Основа эффекта: Использовать Scene Color в URP (или GrabPass в Built-in) для получения доступа к изображению реальной стены, что является обязательным условием для сохранения ее текстуры.Логика смешивания: Реализовать в шейдере режим смешивания Overlay, который комбинирует предварительно "освещенный" цвет краски с цветом сцены, сохраняя при этом детали реального освещения (тени и блики).Визуальное качество: Применить адаптивное сглаживание краев маски на основе экранных производных (fwidth) для достижения максимально качественной и бесшовной интеграции эффекта в реальный мир.Процесс разработки: Следовать гибридному рабочему процессу: быстрое прототипирование и настройка внешнего вида в Shader Graph, с последующим переписыванием на оптимизированный вручную HLSL для производственной версии.Производительность: Проводить строгое профилирование и оптимизацию на целевых мобильных устройствах, уделяя особое внимание минимизации количества инструкций в фрагментном шейдере и управлению фиксированными затратами на захват экрана.6.2 Поэтапный план реализацииПредлагается разделить работу на три логические фазы, что позволит итеративно наращивать функциональность и контролировать качество на каждом этапе.Фаза 1: Базовая функциональность и прототипирование (Shader Graph)Задача 1.1: Настройка ARCameraManager и реализация логики на C# в ARWallPresenter для захвата базовых данных об освещении (например, averageBrightness).Задача 1.2: Создание первоначального Shader Graph. Реализация чтения из Scene Color и базового смешивания Overlay со статичным, заданным в инспекторе цветом краски.Задача 1.3: Интеграция текстуры маски сегментации для управления альфа-каналом (видимостью) эффекта.Цель фазы: Получить работающий, но еще не фотореалистичный эффект окраски стен. Проверить работоспособность основного конвейера (сегментация -> маска -> рендеринг).Фаза 2: Фотореализм и доработка (Shader Graph)Задача 2.1: Реализация полной передачи всех необходимых данных об освещении (цвет, направление света и т.д.) из ARWallPresenter в Shader Graph.Задача 2.2: Реализация логики предварительного освещения цвета краски внутри графа с использованием полученных данных.Задача 2.3: Реализация сглаживания краев на основе smoothstep с настраиваемым параметром мягкости.Цель фазы: Достичь полностью функционального и визуально завершенного фотореалистичного эффекта. Результат этой фазы готов для демонстрации и утверждения художественной составляющей.Фаза 3: Оптимизация и развертывание (HLSL)Задача 3.1: Написание нового, оптимизированного вручную HLSL-шейдера, который в точности воспроизводит функциональность утвержденного Shader Graph. Применение всех тактик из чек-листа оптимизации (Раздел 5.3).Задача 3.2: Замена сглаживания smoothstep на продвинутый метод с использованием экранных производных (fwidth) в HLSL-шейдере.Задача 3.3: Проведение всестороннего профилирования приложения на всех целевых устройствах. Итеративная доработка HLSL-шейдера для достижения целевых показателей производительности (например, <5 мс на GPU для данного эффекта на устройстве среднего класса).Цель фазы: Получить готовую к выпуску, производительную и надежную функциональность, соответствующую всем техническим и визуальным требованиям.